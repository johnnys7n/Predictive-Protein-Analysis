{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Gliomas \n\n<img src='https://www1.racgp.org.au/getattachment/AJGP/2020/April/Current-management-of-cerebral-gliomas/AJGP-04-2020-Clinical-Jeffree-Fig-1.jpg.aspx'>\n    \n## Table of Contents:\n### 1. [Data Information](#data_info) \n### 2. [Data Evaluation](#data_eval)\n### 3. [Modeling](#modeling)\n#### 3.1 [Logistic Regression](#log_reg)\n#### 3.2 [KNNeighbors](#KNN)\n#### 3.3 [Random Forest](#rand_forest)\n### 4. [Hyperparameter Tuning](#hyperparameters)\n### 5. [Summary](#summary)\n\n# 1. Data Information: <a name='data_info'></a>\nAbout the Project:\n> 'Gliomas are the most common primary tumors of the brain. They can be graded as LGG (Lower-Grade Glioma) or GBM (Glioblastoma Multiforme) depending on the histological/imaging criteria. Clinical and molecular/mutation factors are also very crucial for the grading process. Molecular tests are expensive to help accurately diagnose glioma patients.\nIn this dataset, the most frequently mutated 20 genes and 3 clinical features are considered from TCGA-LGG and TCGA-GBM brain glioma projects.'\n\nFeatures:\n1. **Grade ('Target) Binomial Label**\n2. Gender: Categorical \n3. Age_at_diagnosis: Numeric\n4. Race: Categorical\nBelow are the genes of interest\n\n5. IDH1\n6. TP53\n7. ATRX\n8. PTEN\n9. EGFR\n10. CIC\n11. MUC16\n12. PIK3CA\n13. NF1\n14. PIK3R1\n15. FUBP1\n16. RB1\n17. NOTCH1\n18. BCOR\n19. CSMD3\n20. SMARCA4\n21. GRIN2A\n22. IDH2\n23. FAT4\n24. PDGFRA\n\n### Thanks to UCI Machine Learning Repository for Supplying the data:\n<img src=\"https://arispas.com/project/ucidata/featured_hucfe18df49cc0fbcf4abd94baa39c77da_8457_720x2500_fit_q75_h2_lanczos_3.webp\" height=\"400\" width=\"80\">\n\nDataset information: For more information click [Link](https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset)\n\n# 1. Importing the data and tools","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# sklearn tools\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\n\n# sklearn models to test\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# sklearn evaluators\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:40.869003Z","iopub.execute_input":"2023-07-12T20:27:40.869443Z","iopub.status.idle":"2023-07-12T20:27:42.580969Z","shell.execute_reply.started":"2023-07-12T20:27:40.869414Z","shell.execute_reply":"2023-07-12T20:27:42.579428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the data\ndf = pd.read_csv('/kaggle/input/glioma-grading-clinical/TCGA_InfoWithGrade.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:42.583393Z","iopub.execute_input":"2023-07-12T20:27:42.583776Z","iopub.status.idle":"2023-07-12T20:27:42.641998Z","shell.execute_reply.started":"2023-07-12T20:27:42.583745Z","shell.execute_reply":"2023-07-12T20:27:42.640798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Evaluation\n\nQuickly noting the shape, strutcture, and layout of the dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:42.643934Z","iopub.execute_input":"2023-07-12T20:27:42.644279Z","iopub.status.idle":"2023-07-12T20:27:42.696679Z","shell.execute_reply.started":"2023-07-12T20:27:42.644251Z","shell.execute_reply":"2023-07-12T20:27:42.695581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking for missing values\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:42.699477Z","iopub.execute_input":"2023-07-12T20:27:42.699971Z","iopub.status.idle":"2023-07-12T20:27:42.710506Z","shell.execute_reply.started":"2023-07-12T20:27:42.699940Z","shell.execute_reply":"2023-07-12T20:27:42.709122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:42.711782Z","iopub.execute_input":"2023-07-12T20:27:42.712108Z","iopub.status.idle":"2023-07-12T20:27:42.805095Z","shell.execute_reply.started":"2023-07-12T20:27:42.712081Z","shell.execute_reply":"2023-07-12T20:27:42.803742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:42.807095Z","iopub.execute_input":"2023-07-12T20:27:42.807576Z","iopub.status.idle":"2023-07-12T20:27:42.841804Z","shell.execute_reply.started":"2023-07-12T20:27:42.807534Z","shell.execute_reply":"2023-07-12T20:27:42.840627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Grade'].value_counts().plot(kind='bar')\nplt.xticks(rotation=0);","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:42.843321Z","iopub.execute_input":"2023-07-12T20:27:42.844562Z","iopub.status.idle":"2023-07-12T20:27:43.176582Z","shell.execute_reply.started":"2023-07-12T20:27:42.844526Z","shell.execute_reply":"2023-07-12T20:27:43.175769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the X and y datasets\nX = df.drop('Grade', axis = 1)\ny = df.Grade \n\n# checking for inherent correlations\nX_corr = X.corr()\nheat_map = sns.heatmap(X_corr, annot = False)\nheat_map.set(title = 'Heatmap of Correlations');","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:43.177667Z","iopub.execute_input":"2023-07-12T20:27:43.178601Z","iopub.status.idle":"2023-07-12T20:27:43.986622Z","shell.execute_reply.started":"2023-07-12T20:27:43.178569Z","shell.execute_reply":"2023-07-12T20:27:43.985494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_corr.style.background_gradient(cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:43.988455Z","iopub.execute_input":"2023-07-12T20:27:43.989189Z","iopub.status.idle":"2023-07-12T20:27:44.164346Z","shell.execute_reply.started":"2023-07-12T20:27:43.989148Z","shell.execute_reply":"2023-07-12T20:27:44.163091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> because the correlation coefficients between the independent variables seem to be lower than 0.5 for the most part, I will skip the VIF step for testing multicolinearity","metadata":{}},{"cell_type":"markdown","source":"# 3. Modeling <a name=\"modeling\"></a>\n\nHere we will test three different classification models:\n1. LogisticRegression\n2. KNeighborsClassifier\n3. RandomForestClassifier\n\nto see if there are model-specific differences","metadata":{}},{"cell_type":"code","source":"# set the seed\nnp.random.seed(42)\n\n# splitting the data from training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:44.170231Z","iopub.execute_input":"2023-07-12T20:27:44.170730Z","iopub.status.idle":"2023-07-12T20:27:44.178808Z","shell.execute_reply.started":"2023-07-12T20:27:44.170691Z","shell.execute_reply":"2023-07-12T20:27:44.177473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:44.180557Z","iopub.execute_input":"2023-07-12T20:27:44.180958Z","iopub.status.idle":"2023-07-12T20:27:44.195401Z","shell.execute_reply.started":"2023-07-12T20:27:44.180890Z","shell.execute_reply":"2023-07-12T20:27:44.193964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a dictionary of libraries to test\nmodel_grid = {'Logistic': LogisticRegression(),\n             'RandomForest': RandomForestClassifier(),\n              'KNN': KNeighborsClassifier()}\nmodel_score = {} # creating a dictionary of model scores\n\nfor name, model in model_grid.items():\n    model.fit(X_train, y_train)\n    mod_score = model.score(X_test, y_test)\n    model_score[name] = mod_score\n\nmodel_score","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:44.197164Z","iopub.execute_input":"2023-07-12T20:27:44.197675Z","iopub.status.idle":"2023-07-12T20:27:44.723431Z","shell.execute_reply.started":"2023-07-12T20:27:44.197643Z","shell.execute_reply":"2023-07-12T20:27:44.722274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(model_score.values(), model_score.keys()).plot(kind = 'bar');\nplt.xticks(rotation=0);","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:44.725243Z","iopub.execute_input":"2023-07-12T20:27:44.725799Z","iopub.status.idle":"2023-07-12T20:27:44.994575Z","shell.execute_reply.started":"2023-07-12T20:27:44.725760Z","shell.execute_reply":"2023-07-12T20:27:44.993382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seeing that the Logistic model seems to work best, the hyperparameter tuning will be done on this model as a preliminary screen","metadata":{}},{"cell_type":"code","source":"LogisticRegression().get_params().keys()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:44.998174Z","iopub.execute_input":"2023-07-12T20:27:44.999484Z","iopub.status.idle":"2023-07-12T20:27:45.009152Z","shell.execute_reply.started":"2023-07-12T20:27:44.999438Z","shell.execute_reply":"2023-07-12T20:27:45.007754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuning logistic regression\n# building a grid for RandomizedSearchCV\nlog_reg_grid = {'C': np.logspace(-4,4,20),\n               'solver': ['liblinear']}\n\n\nlog_reg_model = RandomizedSearchCV(estimator = LogisticRegression(),\n                                param_distributions= log_reg_grid,\n                                  n_iter= 10,\n                                  cv = 5,\n                                  verbose = True)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:45.010645Z","iopub.execute_input":"2023-07-12T20:27:45.010993Z","iopub.status.idle":"2023-07-12T20:27:45.022750Z","shell.execute_reply.started":"2023-07-12T20:27:45.010967Z","shell.execute_reply":"2023-07-12T20:27:45.021427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg_model.fit(X_train, y_train)\nlog_reg_model.score(X_test, y_test), log_reg_model.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:45.024671Z","iopub.execute_input":"2023-07-12T20:27:45.025054Z","iopub.status.idle":"2023-07-12T20:27:45.517920Z","shell.execute_reply.started":"2023-07-12T20:27:45.025025Z","shell.execute_reply":"2023-07-12T20:27:45.515884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating LogisticRegression model\ny_preds = log_reg_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:45.521936Z","iopub.execute_input":"2023-07-12T20:27:45.522331Z","iopub.status.idle":"2023-07-12T20:27:45.529895Z","shell.execute_reply.started":"2023-07-12T20:27:45.522288Z","shell.execute_reply":"2023-07-12T20:27:45.528672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confustion Matrix\n\n# function to plot the roc_curve:\nplt.style.use('ggplot')\n\ndef plotting_roc_curve(X_test, y_test, model):\n    '''\n    Getting the roc_curve plot from the X_test and y_test input\n    '''\n    y_proba_positive = model.predict_proba(X_test)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_proba_positive)\n    \n    # visualization\n    fig, ax = plt.subplots(figsize = (4,4))\n    ax.plot(fpr, tpr, label = 'ROC')\n    ax.plot([0,1], label = 'True')\n    ax.set(title = 'Plot of the ROC curve',\n           xlabel = 'FPR',\n           ylabel = 'TPR')\n    ax.legend();\n    \nplotting_roc_curve(X_test, y_test, model = log_reg_model)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:45.531252Z","iopub.execute_input":"2023-07-12T20:27:45.532270Z","iopub.status.idle":"2023-07-12T20:27:45.917113Z","shell.execute_reply.started":"2023-07-12T20:27:45.532236Z","shell.execute_reply":"2023-07-12T20:27:45.916007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\ncm = confusion_matrix(y_test, y_preds)\nConfusionMatrixDisplay(cm).plot();","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:45.919098Z","iopub.execute_input":"2023-07-12T20:27:45.919591Z","iopub.status.idle":"2023-07-12T20:27:46.280133Z","shell.execute_reply.started":"2023-07-12T20:27:45.919551Z","shell.execute_reply":"2023-07-12T20:27:46.278874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report","metadata":{}},{"cell_type":"code","source":"score_dict = {'f1_score':f1_score(y_test, y_preds),\n             'recall_score': recall_score(y_test, y_preds),\n             'precision_score':precision_score(y_test, y_preds)}\n\nfor test, score in score_dict.items():\n    print(f'Using the {test}, we see a score of {score *100:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:46.281833Z","iopub.execute_input":"2023-07-12T20:27:46.282288Z","iopub.status.idle":"2023-07-12T20:27:46.300173Z","shell.execute_reply.started":"2023-07-12T20:27:46.282246Z","shell.execute_reply":"2023-07-12T20:27:46.298559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_preds))","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:46.301412Z","iopub.execute_input":"2023-07-12T20:27:46.301751Z","iopub.status.idle":"2023-07-12T20:27:46.318749Z","shell.execute_reply.started":"2023-07-12T20:27:46.301723Z","shell.execute_reply":"2023-07-12T20:27:46.317413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Hyperparameter Tuning <a name=\"hyperparameters\"></a>\nThis time with GridSearchCV","metadata":{}},{"cell_type":"code","source":"LogisticRegression().get_params().keys()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:46.320259Z","iopub.execute_input":"2023-07-12T20:27:46.320716Z","iopub.status.idle":"2023-07-12T20:27:46.328803Z","shell.execute_reply.started":"2023-07-12T20:27:46.320681Z","shell.execute_reply":"2023-07-12T20:27:46.327556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n# defining the hyperparameter grid\nsolvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\npenalty = ['l2', 'l1', 'elasticnet', 'none']\nC = np.logspace(-4,4,20)\n\n# defining the grid search\ngrid = {'solver': solvers,\n       'penalty': penalty,\n       'C': C}\ngrid_search = GridSearchCV(estimator = LogisticRegression(),\n                          param_grid = grid,\n                          cv = 5,\n                          scoring = 'accuracy')\ngrid_result = grid_search.fit(X_train, y_train)\n\n# summarizing the results\nprint(f'Best {grid_result.best_score_} using {grid_result.best_params_}')\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\n\nfor mean, stdev, param in zip(means, stds, params):\n    print(f'Mean :{mean}, std: {stdev}, Params: {param}')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:27:46.330683Z","iopub.execute_input":"2023-07-12T20:27:46.331073Z","iopub.status.idle":"2023-07-12T20:28:42.993673Z","shell.execute_reply.started":"2023-07-12T20:27:46.331044Z","shell.execute_reply":"2023-07-12T20:28:42.992500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_result.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:28:42.995031Z","iopub.execute_input":"2023-07-12T20:28:42.995379Z","iopub.status.idle":"2023-07-12T20:28:43.003378Z","shell.execute_reply.started":"2023-07-12T20:28:42.995351Z","shell.execute_reply":"2023-07-12T20:28:43.002188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotting_roc_curve(X_test, y_test, model = grid_result)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:28:43.005255Z","iopub.execute_input":"2023-07-12T20:28:43.006068Z","iopub.status.idle":"2023-07-12T20:28:43.326757Z","shell.execute_reply.started":"2023-07-12T20:28:43.006037Z","shell.execute_reply":"2023-07-12T20:28:43.325556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f' the ROC_AUC Score is {roc_auc_score(y_test, grid_result.best_estimator_.predict(X_test))}')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:28:43.328711Z","iopub.execute_input":"2023-07-12T20:28:43.329169Z","iopub.status.idle":"2023-07-12T20:28:43.344715Z","shell.execute_reply.started":"2023-07-12T20:28:43.329130Z","shell.execute_reply":"2023-07-12T20:28:43.343252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classication evaluators\ny_preds2 = grid_result.predict(X_test)\nscore_dict = {'f1_score':f1_score(y_test, y_preds2),\n             'recall_score': recall_score(y_test, y_preds2),\n             'precision_score':precision_score(y_test, y_preds2)}\n\nfor test, score in score_dict.items():\n    print(f'Using the {test}, we see a score of {score *100:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:28:43.346417Z","iopub.execute_input":"2023-07-12T20:28:43.346783Z","iopub.status.idle":"2023-07-12T20:28:43.366304Z","shell.execute_reply.started":"2023-07-12T20:28:43.346754Z","shell.execute_reply":"2023-07-12T20:28:43.364811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Summary...For Now <a name=\"summary\"></a>\n\nOut of the three estimators (Logistic Regression, RandomForest, and KNN) we see that the Logistic Regression had a high baseline accuracy score compared to the other models, prompting its evaluation. \n\nAfter a preliminary round of hyperparameter tuning we got a recall score of **93.67%** with Logistic Regression.\n\n \nRecall: Measures the rate of true positives, i.e how many of the actual positive cases are identified/predicted as positive by the model.\n\n$TP/(TP+FN)$","metadata":{}},{"cell_type":"code","source":"# cross validation score:\nfrom sklearn.model_selection import cross_val_score\n\ndef get_cross_val_metrics(model, X, y, cv):\n    '''\n    Getting the cross validation metrics score\n    '''\n    # cross_validation output mean\n    list_of_scores = ['accuracy','f1', 'recall','precision']\n    scores_dict = {}\n    print(f'getting the cross validation metrics with K = {cv}')\n    for score in list_of_scores:\n        scores_dict[score] = np.mean(cross_val_score(model, X, y, cv = cv, verbose = True, scoring = score))\n    print(scores_dict)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:28:43.371877Z","iopub.execute_input":"2023-07-12T20:28:43.372276Z","iopub.status.idle":"2023-07-12T20:28:43.379961Z","shell.execute_reply.started":"2023-07-12T20:28:43.372248Z","shell.execute_reply":"2023-07-12T20:28:43.378666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fitting the model with the best params\nclf = LogisticRegression(C = 1.623776739188721, penalty = 'l1', solver = 'liblinear')\n\n\nget_cross_val_metrics(model = clf, X= X, y= y, cv= 10)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T20:28:43.381582Z","iopub.execute_input":"2023-07-12T20:28:43.382000Z","iopub.status.idle":"2023-07-12T20:28:43.937156Z","shell.execute_reply.started":"2023-07-12T20:28:43.381968Z","shell.execute_reply":"2023-07-12T20:28:43.935959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What Next?\n### Testing other classifiers:\n1. ElasticNet\n2. Naive Bayes\n3. SVC\n4. XGBoost\n5. etc. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}